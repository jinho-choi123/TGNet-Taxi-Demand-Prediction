{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0c6569-8920-4e09-b0b9-a3765b5ea425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777ae96c-8f41-42e4-a9a5-1ce2387ba6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_FOLDER = /Users/ball/Documents/workspace/TGNet/data\n",
      "SAVE_FOLDER = /Users/ball/Documents/workspace/TGNet/data/preprocessed\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "\n",
    "import geopandas as gp\n",
    "\n",
    "from geodatasets import get_path\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import folium\n",
    "import geohash\n",
    "\n",
    "curr_dir = pathlib.Path().absolute()\n",
    "\n",
    "DATA_FOLDER = curr_dir.parent.joinpath('data/')\n",
    "\n",
    "SAVE_FOLDER = DATA_FOLDER.joinpath('preprocessed/')\n",
    "\n",
    "\n",
    "print(f'DATA_FOLDER = {DATA_FOLDER}')\n",
    "print(f'SAVE_FOLDER = {SAVE_FOLDER}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2bb8cf-9065-4dde-b797-d36d7c9a8621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "count     1.274899e+07      1.274899e+07     1.274899e+07       1.274899e+07   \n",
      "mean      1.681491e+00     -7.256184e+01     3.997282e+01      -7.260904e+01   \n",
      "std       1.337924e+00      1.012510e+01     5.578691e+00       9.966037e+00   \n",
      "min       0.000000e+00     -1.219258e+02     0.000000e+00      -7.401667e+02   \n",
      "25%       1.000000e+00     -7.399168e+01     4.073554e+01      -7.399120e+01   \n",
      "50%       1.000000e+00     -7.398160e+01     4.075314e+01      -7.397976e+01   \n",
      "75%       2.000000e+00     -7.396662e+01     4.076757e+01      -7.396246e+01   \n",
      "max       9.000000e+00      7.866265e+01     4.047000e+02       8.527402e+01   \n",
      "\n",
      "       dropoff_latitude  \n",
      "count      1.274899e+07  \n",
      "mean       3.999961e+01  \n",
      "std        5.487742e+00  \n",
      "min       -9.029157e+00  \n",
      "25%        4.073436e+01  \n",
      "50%        4.075362e+01  \n",
      "75%        4.076880e+01  \n",
      "max        4.595333e+02  \n",
      "  tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0  2015-01-15 19:05:39   2015-01-15 19:23:42                1   \n",
      "1  2015-01-10 20:33:38   2015-01-10 20:53:28                1   \n",
      "\n",
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
      "0        -73.993896        40.750111         -73.974785         40.750618  \n",
      "1        -74.001648        40.724243         -73.994415         40.759109  \n"
     ]
    }
   ],
   "source": [
    "# load the data from data/ directory\n",
    "fields = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']\n",
    "\n",
    "taxi_data_2015_01_filename = 'yellow_tripdata_2015-01.csv'\n",
    "taxi_data_2015_01_filename = DATA_FOLDER.joinpath(taxi_data_2015_01_filename)\n",
    "taxi_data_2015_01 = pd.read_csv(taxi_data_2015_01_filename, usecols=fields, engine=\"c\")\n",
    "# for testing, set nrows for speed\n",
    "# taxi_data_2015_01 = pd.read_csv(taxi_data_2015_01_filename, nrows=100000, usecols=fields, engine=\"c\")\n",
    "print(taxi_data_2015_01.describe())\n",
    "print(taxi_data_2015_01.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bc0224-fe08-415d-b500-32aa79c3943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.274899e+07\n",
      "mean     1.681491e+00\n",
      "std      1.337924e+00\n",
      "min      0.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      2.000000e+00\n",
      "max      9.000000e+00\n",
      "Name: passenger_count, dtype: float64\n",
      "  tpep_pickup_datetime tpep_dropoff_datetime  pickup_longitude  \\\n",
      "0  2015-01-15 19:05:39   2015-01-15 19:23:42        -73.993896   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
      "0        40.750111         -73.974785         40.750618  \n",
      "  tpep_pickup_datetime tpep_dropoff_datetime  pickup_longitude  \\\n",
      "0  2015-01-15 19:05:39   2015-01-15 19:23:42        -73.993896   \n",
      "1  2015-01-10 20:33:38   2015-01-10 20:53:28        -74.001648   \n",
      "2  2015-01-10 20:33:38   2015-01-10 20:43:41        -73.963341   \n",
      "\n",
      "   pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
      "0        40.750111         -73.974785         40.750618  \n",
      "1        40.724243         -73.994415         40.759109  \n",
      "2        40.802788         -73.951820         40.824413  \n"
     ]
    }
   ],
   "source": [
    "# remove rows that passenger_count is <= 0 or >= 5\n",
    "print(taxi_data_2015_01.passenger_count.describe())\n",
    "taxi_data_2015_01 = taxi_data_2015_01[(taxi_data_2015_01.passenger_count >= 1) | (taxi_data_2015_01.passenger_count <= 4)]\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01.drop(columns=['passenger_count'])\n",
    "print(taxi_data_2015_01.head(1))\n",
    "\n",
    "print(taxi_data_2015_01.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60224188-465b-4fa6-a158-b529dcf3bbdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filter'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/series.py:1298\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_with_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# We have a scalar (or for MultiIndex or object-dtype, scalar-like)\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;66;03m#  key that is not present in self.index.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/series.py:1370\u001b[0m, in \u001b[0;36mSeries._set_with_engine\u001b[0;34m(self, key, value, warn)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_with_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value, warn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1370\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;66;03m# this is equivalent to self._values[key] = value\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filter'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# remove rows that gap between tpep_pickup_datetime - tpep_dropoff_datetime is neg or more than 1 hours\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m taxi_data_2015_01 \u001b[38;5;241m=\u001b[39m \u001b[43mtaxi_data_2015_01\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_pickup_dropoff_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m taxi_data_2015_01 \u001b[38;5;241m=\u001b[39m taxi_data_2015_01[taxi_data_2015_01[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpep_dropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(taxi_data_2015_01\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mfilter_pickup_dropoff_time\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     11\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m---> 13\u001b[0m     \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/series.py:1322\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_values(key, value)\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# GH#12862 adding a new key to the Series\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# The key was OK, but we cannot set the value losslessly\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:2238\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# TODO: re-issue this with setitem-specific message?\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m   2234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of Index.insert with object-dtype is deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2236\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   2237\u001b[0m     )\n\u001b[0;32m-> 2238\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;66;03m# we have a coerced indexer, e.g. a float\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;66;03m# that matches in an int64 Index, so\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;66;03m# we will not create a duplicate index, rather\u001b[39;00m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;66;03m# index to that element\u001b[39;00m\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;66;03m# e.g. 0.0 -> 0\u001b[39;00m\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;66;03m# GH#12246\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;66;03m# pass new_index[-1:] instead if [new_index[-1]]\u001b[39;00m\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;66;03m#  so that we retain dtype\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7003\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   6997\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[1;32m   6998\u001b[0m ):\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[1;32m   7000\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[1;32m   7001\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[1;32m   7002\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n\u001b[0;32m-> 7003\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7006\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"insert\" matches argument types\u001b[39;00m\n\u001b[1;32m   7007\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"int\", \"None\"\u001b[39;00m\n\u001b[1;32m   7008\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(arr, loc, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/workspace/TGNet/.venv/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:5670\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5668\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(index, index\u001b[38;5;241m+\u001b[39mnumnew)\n\u001b[1;32m   5669\u001b[0m new[\u001b[38;5;28mtuple\u001b[39m(slobj)] \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m-> 5670\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnumnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5671\u001b[0m slobj2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m ndim\n\u001b[1;32m   5672\u001b[0m slobj2[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(index, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def filter_pickup_dropoff_time(row):\n",
    "    pickup_time = row['tpep_pickup_datetime']\n",
    "    dropoff_time = row['tpep_dropoff_datetime']\n",
    "    \n",
    "    pickup_time_obj = datetime.strptime(pickup_time, '%Y-%m-%d %H:%M:%S')\n",
    "    dropoff_time_obj = datetime.strptime(dropoff_time, '%Y-%m-%d %H:%M:%S')\n",
    "    if pickup_time_obj >= dropoff_time_obj:\n",
    "        # invalid time\n",
    "        row['filter']=False\n",
    "    elif dropoff_time_obj - pickup_time_obj > timedelta(hours=1):\n",
    "        row['filter']=False\n",
    "    else: \n",
    "        row['filter']=True\n",
    "    return row\n",
    "    \n",
    "\n",
    "\n",
    "# remove rows that gap between tpep_pickup_datetime - tpep_dropoff_datetime is neg or more than 1 hours\n",
    "taxi_data_2015_01 = taxi_data_2015_01.apply(filter_pickup_dropoff_time, axis=1)\n",
    "taxi_data_2015_01 = taxi_data_2015_01[taxi_data_2015_01['filter']].drop(columns=['filter', 'tpep_dropoff_datetime'])\n",
    "print(taxi_data_2015_01.head(1))\n",
    "# remove rows that dates are not in year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752e9f2-468d-4aa6-b158-d9bc9f531005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the date part\n",
    "# change tpep_pickup_datetime 2015-01-15 19:05:39 into 2015-01-15-19-0\n",
    "taxi_data_2015_01_datetime = taxi_data_2015_01.loc[:, 'tpep_pickup_datetime']\n",
    "\n",
    "def convert_datetime(datetime_string):\n",
    "    datetime_obj = datetime.strptime(datetime_string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # if minute is 0~29, then set minute = 0\n",
    "    # else, set minute=30\n",
    "    if datetime_obj.minute >= 30:\n",
    "        minute = 30 \n",
    "    else:\n",
    "        minute = 0\n",
    "    return datetime_obj.replace(minute=minute).strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "\n",
    "taxi_data_2015_01_datetime = taxi_data_2015_01_datetime.apply(convert_datetime)\n",
    "taxi_data_2015_01_datetime = taxi_data_2015_01_datetime.rename(\"pickup_datetime\")\n",
    "\n",
    "# print(taxi_data_2015_01_datetime)\n",
    "\n",
    "# append it to taxi_data_2015_01\n",
    "taxi_data_2015_01 = taxi_data_2015_01.join(taxi_data_2015_01_datetime)\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01.drop('tpep_pickup_datetime', axis=1)\n",
    "print(taxi_data_2015_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bc689-68d9-4a6f-aa7d-e71f5d79255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter if there are any invalid longitude, latitude\n",
    "# NYC long range: -74.3 ~ -73.8\n",
    "# NYC lat range: 40.4 ~ 41\n",
    "taxi_data_2015_01 = taxi_data_2015_01[(taxi_data_2015_01.pickup_longitude >= -74.3) & (taxi_data_2015_01.pickup_longitude <= -73.6)]\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01[(taxi_data_2015_01.dropoff_longitude >= -74.1) & (taxi_data_2015_01.dropoff_longitude <= -73.5)]\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01[(taxi_data_2015_01.pickup_latitude >= 40.4) & (taxi_data_2015_01.pickup_latitude <= 41)]\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01[(taxi_data_2015_01.dropoff_latitude >= 40.3) & (taxi_data_2015_01.dropoff_latitude <= 41.1)]\n",
    "\n",
    "# check the max, min longitude and latitude\n",
    "print(f'Max pickup longitude: {taxi_data_2015_01.pickup_longitude.max()}')\n",
    "print(f'Min pickup longitude: {taxi_data_2015_01.pickup_longitude.min()}')\n",
    "\n",
    "print(f'Max pickup latitude: {taxi_data_2015_01.pickup_latitude.max()}')\n",
    "print(f'Min pickup latitude: {taxi_data_2015_01.pickup_latitude.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dc7f0-9db4-435b-ab9b-2432383bc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert long, lat into geohash\n",
    "def convert_geohash(row):\n",
    "    pickup_lat, pickup_lng = row['pickup_latitude'], row['pickup_longitude']\n",
    "    dropoff_lat, dropoff_lng = row['dropoff_latitude'], row['dropoff_longitude']\n",
    "\n",
    "    row['pickup_geohash'] = geohash.encode(latitude=pickup_lat, longitude=pickup_lng, precision=10)\n",
    "    row['dropoff_geohash'] = geohash.encode(latitude=dropoff_lat, longitude=dropoff_lng, precision=10)\n",
    "    return row \n",
    "\n",
    "\n",
    "taxi_data_2015_01 = taxi_data_2015_01.apply(convert_geohash, axis=1)\n",
    "taxi_data_2015_01 = taxi_data_2015_01.drop(columns=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "\n",
    "print(taxi_data_2015_01.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b000c-ec01-4d65-b2d4-cd2e60c6dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed file\n",
    "# for fast read speed, we will store as parquet format\n",
    "file_name = 'taxi_data_2015_01_preprocessed.parquet.gzip'\n",
    "file_path = SAVE_FOLDER.joinpath(file_name)\n",
    "file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "taxi_data_2015_01.to_parquet(file_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d9ba2-8848-45f4-af5d-a01ed0c32814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
